{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MelBand RoFormer - Audio Source Separation\n",
    "\n",
    "This notebook demonstrates how to use MelBand RoFormer for separating vocals from instrumentals.\n",
    "\n",
    "**Features:**\n",
    "- Separate vocals from music\n",
    "- High-quality source separation using transformer architecture\n",
    "- Multiple pre-trained models available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install melband-roformer-infer package\n",
    "!pip install -q git+https://github.com/openmirlab/melband-roformer-infer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Model\n",
    "\n",
    "We'll use the **MelBand Roformer Kim** model, which is excellent for vocal separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "!mkdir -p models/melband-roformer-kim\n",
    "!mkdir -p input_songs\n",
    "!mkdir -p outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model checkpoint from Hugging Face\n",
    "!wget -q -O models/melband-roformer-kim/MelBandRoformer.ckpt \\\n",
    "    \"https://huggingface.co/KimberleyJSN/melbandroformer/resolve/main/MelBandRoformer.ckpt\"\n",
    "\n",
    "# Copy bundled config from the installed package\n",
    "import shutil\n",
    "from mel_band_roformer import __file__ as pkg_file\n",
    "from pathlib import Path\n",
    "\n",
    "pkg_dir = Path(pkg_file).parent\n",
    "config_src = pkg_dir / \"configs\" / \"config_vocals_mel_band_roformer.yaml\"\n",
    "config_dst = Path(\"models/melband-roformer-kim/config.yaml\")\n",
    "shutil.copy(config_src, config_dst)\n",
    "\n",
    "print(\"Model and config ready!\")\n",
    "!ls -lh models/melband-roformer-kim/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload Your Audio File\n",
    "\n",
    "Upload a `.wav` file to separate vocals from instrumentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload from your computer\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your audio file (.wav format):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move uploaded file to input folder\n",
    "for filename in uploaded.keys():\n",
    "    !mv \"{filename}\" input_songs/\n",
    "    print(f\"Moved {filename} to input_songs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Use a sample audio (uncomment to use)\n",
    "# !wget -q -O input_songs/sample.wav \"YOUR_AUDIO_URL_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check input files\n",
    "!ls -lh input_songs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Source Separation\n",
    "\n",
    "Select your preferred method and run the separation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Select Inference Method { display-mode: \"form\" }\n",
    "#@markdown Choose which method to use for audio separation:\n",
    "\n",
    "inference_method = \"CLI (Command Line)\" #@param [\"CLI (Command Line)\", \"Python API\"]\n",
    "\n",
    "print(f\"Selected method: {inference_method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run Source Separation { display-mode: \"form\" }\n",
    "#@markdown Click the play button to run separation with your selected method.\n",
    "\n",
    "if inference_method == \"CLI (Command Line)\":\n",
    "    # ============================================\n",
    "    # Option A: CLI (Command Line)\n",
    "    # ============================================\n",
    "    print(\"Running with CLI...\\n\")\n",
    "    !melband-roformer-infer \\\n",
    "        --config_path models/melband-roformer-kim/config.yaml \\\n",
    "        --model_path models/melband-roformer-kim/MelBandRoformer.ckpt \\\n",
    "        --input_folder ./input_songs \\\n",
    "        --store_dir ./outputs\n",
    "\n",
    "else:\n",
    "    # ============================================\n",
    "    # Option B: Python API\n",
    "    # ============================================\n",
    "    print(\"Running with Python API...\\n\")\n",
    "    \n",
    "    import torch\n",
    "    import yaml\n",
    "    import soundfile as sf\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "    from ml_collections import ConfigDict\n",
    "    from mel_band_roformer.utils import get_model_from_config, demix_track\n",
    "\n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    with open(\"models/melband-roformer-kim/config.yaml\") as f:\n",
    "        config = ConfigDict(yaml.safe_load(f))\n",
    "\n",
    "    model = get_model_from_config(\"mel_band_roformer\", config)\n",
    "    model.load_state_dict(\n",
    "        torch.load(\"models/melband-roformer-kim/MelBandRoformer.ckpt\", map_location=\"cpu\")\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded on {device}\\n\")\n",
    "\n",
    "    # Process files\n",
    "    input_folder = Path(\"input_songs\")\n",
    "    output_folder = Path(\"outputs\")\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    for audio_path in input_folder.glob(\"*.wav\"):\n",
    "        print(f\"Processing: {audio_path.name}\")\n",
    "        \n",
    "        # Load audio\n",
    "        mix, sr = sf.read(audio_path)\n",
    "        original_mono = len(mix.shape) == 1\n",
    "        if original_mono:\n",
    "            mix = np.stack([mix, mix], axis=-1)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        mixture = torch.tensor(mix.T, dtype=torch.float32)\n",
    "        \n",
    "        # Run separation\n",
    "        with torch.no_grad():\n",
    "            result, _ = demix_track(config, model, mixture, device)\n",
    "        \n",
    "        # Save vocals\n",
    "        stem_name = audio_path.stem\n",
    "        for instrument, audio in result.items():\n",
    "            output = audio.T\n",
    "            if original_mono:\n",
    "                output = output[:, 0]\n",
    "            output_path = output_folder / f\"{stem_name}_{instrument}.wav\"\n",
    "            sf.write(output_path, output, sr, subtype=\"FLOAT\")\n",
    "            print(f\"  Saved: {output_path}\")\n",
    "        \n",
    "        # Save instrumental (original - vocals)\n",
    "        vocals = result.get(\"vocals\", list(result.values())[0]).T\n",
    "        if original_mono:\n",
    "            vocals = vocals[:, 0]\n",
    "            mix = mix[:, 0]\n",
    "        instrumental = mix - vocals\n",
    "        instrumental_path = output_folder / f\"{stem_name}_instrumental.wav\"\n",
    "        sf.write(instrumental_path, instrumental, sr, subtype=\"FLOAT\")\n",
    "        print(f\"  Saved: {instrumental_path}\")\n",
    "\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output files\n",
    "!ls -lh outputs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Listen to Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Find and display all output files\n",
    "for audio_file in sorted(output_dir.glob(\"*.wav\")):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"File: {audio_file.name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    display(ipd.Audio(str(audio_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all output files as a zip\n",
    "!zip -r outputs.zip outputs/\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"outputs.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Available Models\n",
    "\n",
    "| Model | Description | Best For |\n",
    "|-------|-------------|----------|\n",
    "| MelBand Roformer Kim | Original vocal separation | General vocal extraction |\n",
    "| MelBand Roformer Big Beta 6 | Larger model by unwa | Higher quality |\n",
    "| MelBand Roformer Karaoke | Karaoke-optimized | Background vocal removal |\n",
    "| MelBand Roformer Denoise | Noise reduction | Cleaning audio |\n",
    "\n",
    "See the [model registry](https://github.com/openmirlab/melband-roformer-infer) for more options."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
